{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simclr_finetune.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manmeet3/Medical-SSL-SimCLRv2/blob/main/simclr_lymphoma.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cprhws0py3zv"
      },
      "source": [
        "This colab contains a first attempt at finetuning simclr for medical dataset.\n",
        "To do: \n",
        "* Maybe follow through all the steps in simclr architecture to get best performance? pretrain -> finetune -> distill -> infer\n",
        "* Wrap the model in a tfx pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAXCw3GaVaF9"
      },
      "source": [
        "Chest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, Openi was the largest publicly available source of chest X-ray images with 4,143 images available.\n",
        "\n",
        "This NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" (Wang et al.)\n",
        "\n",
        "Source: Kaggle dataset description (https://www.kaggle.com/nih-chest-xrays/data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bF7SU32FsJrd"
      },
      "source": [
        "SimCLRv2 reference colab: https://github.com/google-research/simclr/tree/master/colabs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br230Wnh32gd"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_eager_execution()\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uZnwXlwy0QV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2126267-1bca-4928-9882-d1217443a358"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf7QtWO43C1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ba4270-86d9-45cf-9f03-559e910a536a"
      },
      "source": [
        "%cd /content/drive/Shared\\ drives/DL2-project/DL2_SimCLRv2_Medical_Classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/Shared drives/DL2-project/DL2_SimCLRv2_Medical_Classification\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmOq9-G_mHrO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2c00b40-5b1d-4dc1-82ac-a804754dfb04"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive  Data_Entry_2017.gsheet  Links.gdoc  simclr_finetune.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB9gqqIt34VI"
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"manmeet3\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"0948ff0e9e993e3c5d69de02ca1b882f\" # key from the json file"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtIobv564Bo6",
        "outputId": "fa503f98-aa2f-46f4-afc3-c6d803ca9ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!kaggle datasets download -d andrewmvd/malignant-lymphoma-classification"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading malignant-lymphoma-classification.zip to /content/drive/Shareddrives/DL2-project/DL2_SimCLRv2_Medical_Classification\n",
            " 99% 1.33G/1.34G [00:18<00:00, 53.7MB/s]\n",
            "100% 1.34G/1.34G [00:18<00:00, 77.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYxsfIOjWi7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c38d156f-81dd-4795-ab26-44fbada424f9"
      },
      "source": [
        "!unzip malignant-lymphoma-classification.zip"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  malignant-lymphoma-classification.zip\n",
            "  inflating: CLL/sj-03-2810_001.tif  \n",
            "  inflating: CLL/sj-03-2810_002.tif  \n",
            "  inflating: CLL/sj-03-2810_003.tif  \n",
            "  inflating: CLL/sj-03-2810_004.tif  \n",
            "  inflating: CLL/sj-03-2810_005.tif  \n",
            "  inflating: CLL/sj-03-2810_006.tif  \n",
            "  inflating: CLL/sj-03-2810_007.tif  \n",
            "  inflating: CLL/sj-03-2810_008.tif  \n",
            "  inflating: CLL/sj-03-2810_009.tif  \n",
            "  inflating: CLL/sj-03-2810_010.tif  \n",
            "  inflating: CLL/sj-03-2810_011.tif  \n",
            "  inflating: CLL/sj-03-476_001.tif   \n",
            "  inflating: CLL/sj-03-476_002.tif   \n",
            "  inflating: CLL/sj-03-476_003.tif   \n",
            "  inflating: CLL/sj-03-476_004.tif   \n",
            "  inflating: CLL/sj-03-476_005.tif   \n",
            "  inflating: CLL/sj-03-476_006.tif   \n",
            "  inflating: CLL/sj-03-476_007.tif   \n",
            "  inflating: CLL/sj-03-476_008.tif   \n",
            "  inflating: CLL/sj-03-476_009.tif   \n",
            "  inflating: CLL/sj-03-476_010.tif   \n",
            "  inflating: CLL/sj-03-4957_001.tif  \n",
            "  inflating: CLL/sj-03-4957_002.tif  \n",
            "  inflating: CLL/sj-03-4957_003.tif  \n",
            "  inflating: CLL/sj-03-4957_004.tif  \n",
            "  inflating: CLL/sj-03-4957_005.tif  \n",
            "  inflating: CLL/sj-03-4957_006.tif  \n",
            "  inflating: CLL/sj-03-4957_007.tif  \n",
            "  inflating: CLL/sj-03-4957_008.tif  \n",
            "  inflating: CLL/sj-03-4957_009.tif  \n",
            "  inflating: CLL/sj-03-4957_010.tif  \n",
            "  inflating: CLL/sj-03-5521_001.tif  \n",
            "  inflating: CLL/sj-03-5521_002.tif  \n",
            "  inflating: CLL/sj-03-5521_003.tif  \n",
            "  inflating: CLL/sj-03-5521_004.tif  \n",
            "  inflating: CLL/sj-03-5521_005.tif  \n",
            "  inflating: CLL/sj-03-5521_006.tif  \n",
            "  inflating: CLL/sj-03-5521_007.tif  \n",
            "  inflating: CLL/sj-03-5521_008.tif  \n",
            "  inflating: CLL/sj-03-5521_009.tif  \n",
            "  inflating: CLL/sj-03-5521_010.tif  \n",
            "  inflating: CLL/sj-03-852-R2_001.tif  \n",
            "  inflating: CLL/sj-03-852-R2_002.tif  \n",
            "  inflating: CLL/sj-03-852-R2_003.tif  \n",
            "  inflating: CLL/sj-03-852-R2_004.tif  \n",
            "  inflating: CLL/sj-03-852-R2_005.tif  \n",
            "  inflating: CLL/sj-03-852-R2_006.tif  \n",
            "  inflating: CLL/sj-03-852-R2_007.tif  \n",
            "  inflating: CLL/sj-03-852-R2_008.tif  \n",
            "  inflating: CLL/sj-03-852-R2_009.tif  \n",
            "  inflating: CLL/sj-03-852-R2_010.tif  \n",
            "  inflating: CLL/sj-03-852-R2_011.tif  \n",
            "  inflating: CLL/sj-03-852-R2_012.tif  \n",
            "  inflating: CLL/sj-03-852-R2_013.tif  \n",
            "  inflating: CLL/sj-03-852-R2_014.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_001.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_002.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_003.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_004.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_005.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_006.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_007.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_008.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_009.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_010.tif  \n",
            "  inflating: CLL/sj-05-1396-R3_011.tif  \n",
            "  inflating: CLL/sj-05-3165_001.tif  \n",
            "  inflating: CLL/sj-05-3165_002.tif  \n",
            "  inflating: CLL/sj-05-3165_003.tif  \n",
            "  inflating: CLL/sj-05-3165_004.tif  \n",
            "  inflating: CLL/sj-05-3165_005.tif  \n",
            "  inflating: CLL/sj-05-3165_006.tif  \n",
            "  inflating: CLL/sj-05-3165_007.tif  \n",
            "  inflating: CLL/sj-05-3165_008.tif  \n",
            "  inflating: CLL/sj-05-3165_009.tif  \n",
            "  inflating: CLL/sj-05-3165_010.tif  \n",
            "  inflating: CLL/sj-05-3165_011.tif  \n",
            "  inflating: CLL/sj-05-3165_012.tif  \n",
            "  inflating: CLL/sj-05-3344_001.tif  \n",
            "  inflating: CLL/sj-05-3344_002.tif  \n",
            "  inflating: CLL/sj-05-3344_003.tif  \n",
            "  inflating: CLL/sj-05-3344_004.tif  \n",
            "  inflating: CLL/sj-05-3344_005.tif  \n",
            "  inflating: CLL/sj-05-3344_006.tif  \n",
            "  inflating: CLL/sj-05-3344_007.tif  \n",
            "  inflating: CLL/sj-05-3344_008.tif  \n",
            "  inflating: CLL/sj-05-3344_009.tif  \n",
            "  inflating: CLL/sj-05-3344_010.tif  \n",
            "  inflating: CLL/sj-05-3344_011.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_001.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_002.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_003.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_004.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_005.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_006.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_007.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_008.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_009.tif  \n",
            "  inflating: CLL/sj-05-3874-R2_010.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_002.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_003.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_004.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_005.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_006.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_007.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_008.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_009.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_010.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_011.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_012.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_013.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_014.tif  \n",
            "  inflating: CLL/sj-05-5269-R10_015.tif  \n",
            "  inflating: FL/sj-05-1467-R1_001.tif  \n",
            "  inflating: FL/sj-05-1467-R1_002.tif  \n",
            "  inflating: FL/sj-05-1467-R1_003.tif  \n",
            "  inflating: FL/sj-05-1467-R1_004.tif  \n",
            "  inflating: FL/sj-05-1467-R1_005.tif  \n",
            "  inflating: FL/sj-05-1467-R1_006.tif  \n",
            "  inflating: FL/sj-05-1467-R1_007.tif  \n",
            "  inflating: FL/sj-05-1467-R1_008.tif  \n",
            "  inflating: FL/sj-05-1467-R1_009.tif  \n",
            "  inflating: FL/sj-05-1467-R1_010.tif  \n",
            "  inflating: FL/sj-05-1467-R1_011.tif  \n",
            "  inflating: FL/sj-05-1881-R1_001.tif  \n",
            "  inflating: FL/sj-05-1881-R1_002.tif  \n",
            "  inflating: FL/sj-05-1881-R1_003.tif  \n",
            "  inflating: FL/sj-05-1881-R1_004.tif  \n",
            "  inflating: FL/sj-05-1881-R1_005.tif  \n",
            "  inflating: FL/sj-05-1881-R1_006.tif  \n",
            "  inflating: FL/sj-05-1881-R1_007.tif  \n",
            "  inflating: FL/sj-05-1881-R1_008.tif  \n",
            "  inflating: FL/sj-05-1881-R1_009.tif  \n",
            "  inflating: FL/sj-05-1881-R1_010.tif  \n",
            "  inflating: FL/sj-05-1881-R1_011.tif  \n",
            "  inflating: FL/sj-05-1881-R1_012.tif  \n",
            "  inflating: FL/sj-05-1881-R1_013.tif  \n",
            "  inflating: FL/sj-05-1881-R1_014.tif  \n",
            "  inflating: FL/sj-05-1881-R1_015.tif  \n",
            "  inflating: FL/sj-05-1881-R1_016.tif  \n",
            "  inflating: FL/sj-05-1881-R1_017.tif  \n",
            "  inflating: FL/sj-05-1881-R1_018.tif  \n",
            "  inflating: FL/sj-05-1881-R1_019.tif  \n",
            "  inflating: FL/sj-05-4881-R3_001.tif  \n",
            "  inflating: FL/sj-05-4881-R3_002.tif  \n",
            "  inflating: FL/sj-05-4881-R3_003.tif  \n",
            "  inflating: FL/sj-05-4881-R3_004.tif  \n",
            "  inflating: FL/sj-05-4881-R3_005.tif  \n",
            "  inflating: FL/sj-05-4881-R3_006.tif  \n",
            "  inflating: FL/sj-05-4881-R3_007.tif  \n",
            "  inflating: FL/sj-05-4881-R3_008.tif  \n",
            "  inflating: FL/sj-05-4881-R3_009.tif  \n",
            "  inflating: FL/sj-05-4881-R3_010.tif  \n",
            "  inflating: FL/sj-05-5311-R1_001.tif  \n",
            "  inflating: FL/sj-05-5311-R1_002.tif  \n",
            "  inflating: FL/sj-05-5311-R1_003.tif  \n",
            "  inflating: FL/sj-05-5311-R1_004.tif  \n",
            "  inflating: FL/sj-05-5311-R1_005.tif  \n",
            "  inflating: FL/sj-05-5311-R1_006.tif  \n",
            "  inflating: FL/sj-05-5311-R1_007.tif  \n",
            "  inflating: FL/sj-05-5311-R1_008.tif  \n",
            "  inflating: FL/sj-05-5311-R1_009.tif  \n",
            "  inflating: FL/sj-05-5311-R1_010.tif  \n",
            "  inflating: FL/sj-05-5311-R1_011.tif  \n",
            "  inflating: FL/sj-05-5311-R1_012.tif  \n",
            "  inflating: FL/sj-05-5311-R1_013.tif  \n",
            "  inflating: FL/sj-05-5389-R1_001.tif  \n",
            "  inflating: FL/sj-05-5389-R1_002.tif  \n",
            "  inflating: FL/sj-05-5389-R1_003.tif  \n",
            "  inflating: FL/sj-05-5389-R1_004.tif  \n",
            "  inflating: FL/sj-05-5389-R1_005.tif  \n",
            "  inflating: FL/sj-05-5389-R1_006.tif  \n",
            "  inflating: FL/sj-05-5389-R1_007.tif  \n",
            "  inflating: FL/sj-05-5389-R1_008.tif  \n",
            "  inflating: FL/sj-05-5389-R1_009.tif  \n",
            "  inflating: FL/sj-05-5389-R1_010.tif  \n",
            "  inflating: FL/sj-05-5389-R1_011.tif  \n",
            "  inflating: FL/sj-05-5389-R1_012.tif  \n",
            "  inflating: FL/sj-05-5389-R1_013.tif  \n",
            "  inflating: FL/sj-05-5389-R1_014.tif  \n",
            "  inflating: FL/sj-05-5389-R1_015.tif  \n",
            "  inflating: FL/sj-05-5389-R1_016.tif  \n",
            "  inflating: FL/sj-05-5389-R1_017.tif  \n",
            "  inflating: FL/sj-05-5389-R1_018.tif  \n",
            "  inflating: FL/sj-05-5389-R1_019.tif  \n",
            "  inflating: FL/sj-05-5829_001.tif   \n",
            "  inflating: FL/sj-05-5829_002.tif   \n",
            "  inflating: FL/sj-05-5829_003.tif   \n",
            "  inflating: FL/sj-05-5829_004.tif   \n",
            "  inflating: FL/sj-05-5829_005.tif   \n",
            "  inflating: FL/sj-05-5829_006.tif   \n",
            "  inflating: FL/sj-05-5829_007.tif   \n",
            "  inflating: FL/sj-05-5829_008.tif   \n",
            "  inflating: FL/sj-05-5829_009.tif   \n",
            "  inflating: FL/sj-05-5829_010.tif   \n",
            "  inflating: FL/sj-05-5829_011.tif   \n",
            "  inflating: FL/sj-05-5829_012.tif   \n",
            "  inflating: FL/sj-05-588-R1_001.tif  \n",
            "  inflating: FL/sj-05-588-R1_002.tif  \n",
            "  inflating: FL/sj-05-588-R1_003.tif  \n",
            "  inflating: FL/sj-05-588-R1_004.tif  \n",
            "  inflating: FL/sj-05-588-R1_005.tif  \n",
            "  inflating: FL/sj-05-588-R1_006.tif  \n",
            "  inflating: FL/sj-05-588-R1_007.tif  \n",
            "  inflating: FL/sj-05-588-R1_008.tif  \n",
            "  inflating: FL/sj-05-588-R1_009.tif  \n",
            "  inflating: FL/sj-05-588-R1_010.tif  \n",
            "  inflating: FL/sj-05-6124-R3_001.tif  \n",
            "  inflating: FL/sj-05-6124-R3_002.tif  \n",
            "  inflating: FL/sj-05-6124-R3_003.tif  \n",
            "  inflating: FL/sj-05-6124-R3_004.tif  \n",
            "  inflating: FL/sj-05-6124-R3_005.tif  \n",
            "  inflating: FL/sj-05-6124-R3_006.tif  \n",
            "  inflating: FL/sj-05-6124-R3_007.tif  \n",
            "  inflating: FL/sj-05-6124-R3_008.tif  \n",
            "  inflating: FL/sj-05-6124-R3_009.tif  \n",
            "  inflating: FL/sj-05-6124-R3_010.tif  \n",
            "  inflating: FL/sj-05-6124-R3_011.tif  \n",
            "  inflating: FL/sj-05-6124-R3_012.tif  \n",
            "  inflating: FL/sj-05-6124-R3_013.tif  \n",
            "  inflating: FL/sj-05-6124-R3_014.tif  \n",
            "  inflating: FL/sj-05-6124-R3_015.tif  \n",
            "  inflating: FL/sj-05-6124-R4_001.tif  \n",
            "  inflating: FL/sj-05-6124-R4_002.tif  \n",
            "  inflating: FL/sj-05-6124-R4_003.tif  \n",
            "  inflating: FL/sj-05-6124-R4_004.tif  \n",
            "  inflating: FL/sj-05-6124-R4_005.tif  \n",
            "  inflating: FL/sj-05-6124-R4_006.tif  \n",
            "  inflating: FL/sj-05-6124-R4_007.tif  \n",
            "  inflating: FL/sj-05-6124-R4_008.tif  \n",
            "  inflating: FL/sj-05-6124-R4_009.tif  \n",
            "  inflating: FL/sj-05-6124-R4_010.tif  \n",
            "  inflating: FL/sj-05-6124-R4_011.tif  \n",
            "  inflating: FL/sj-05-6124-R4_012.tif  \n",
            "  inflating: FL/sj-05-6124-R4_013.tif  \n",
            "  inflating: FL/sj-05-6124-R4_014.tif  \n",
            "  inflating: FL/sj-05-6124-R4_015.tif  \n",
            "  inflating: FL/sj-05-6124-R4_016.tif  \n",
            "  inflating: FL/sj-05-894-R3_001.tif  \n",
            "  inflating: FL/sj-05-894-R3_002.tif  \n",
            "  inflating: FL/sj-05-894-R3_003.tif  \n",
            "  inflating: FL/sj-05-894-R3_004.tif  \n",
            "  inflating: FL/sj-05-894-R3_005.tif  \n",
            "  inflating: FL/sj-05-894-R3_006.tif  \n",
            "  inflating: FL/sj-05-894-R3_007.tif  \n",
            "  inflating: FL/sj-05-894-R3_008.tif  \n",
            "  inflating: FL/sj-05-894-R3_009.tif  \n",
            "  inflating: FL/sj-05-894-R3_010.tif  \n",
            "  inflating: FL/sj-05-894-R3_011.tif  \n",
            "  inflating: FL/sj-05-894-R3_012.tif  \n",
            "  inflating: FL/sj-05-894-R3_013.tif  \n",
            "  inflating: FL/sj-05-894-R3_014.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_001.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_002.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_003.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_004.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_005.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_006.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_007.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_008.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_009.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_010.tif  \n",
            "  inflating: MCL/sj-04-3077-R2_011.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_001.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_002.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_003.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_004.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_005.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_006.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_007.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_008.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_009.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_010.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_011.tif  \n",
            "  inflating: MCL/sj-04-4525-R4_012.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_001.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_002.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_003.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_004.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_005.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_006.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_007.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_008.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_009.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_010.tif  \n",
            "  inflating: MCL/sj-04-4967-R2_011.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_001.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_002.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_003.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_004.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_005.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_006.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_007.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_008.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_009.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_010.tif  \n",
            "  inflating: MCL/sj-04-6010-R3_011.tif  \n",
            "  inflating: MCL/sj-05-1374_001.tif  \n",
            "  inflating: MCL/sj-05-1374_002.tif  \n",
            "  inflating: MCL/sj-05-1374_003.tif  \n",
            "  inflating: MCL/sj-05-1374_004.tif  \n",
            "  inflating: MCL/sj-05-1374_005.tif  \n",
            "  inflating: MCL/sj-05-1374_006.tif  \n",
            "  inflating: MCL/sj-05-1374_007.tif  \n",
            "  inflating: MCL/sj-05-1374_008.tif  \n",
            "  inflating: MCL/sj-05-1374_009.tif  \n",
            "  inflating: MCL/sj-05-1374_010.tif  \n",
            "  inflating: MCL/sj-05-1374_011.tif  \n",
            "  inflating: MCL/sj-05-1374_012.tif  \n",
            "  inflating: MCL/sj-05-1374_013.tif  \n",
            "  inflating: MCL/sj-05-1374_014.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_001.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_002.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_003.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_004.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_005.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_006.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_007.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_008.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_009.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_010.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_011.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_012.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_013.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_014.tif  \n",
            "  inflating: MCL/sj-05-3362-R2_015.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_002.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_003.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_004.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_005.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_006.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_007.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_008.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_009.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_010.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_011.tif  \n",
            "  inflating: MCL/sj-05-4179-R1_012.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_001.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_002.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_003.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_004.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_005.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_006.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_007.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_008.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_009.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_010.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_011.tif  \n",
            "  inflating: MCL/sj-05-5326-R1_012.tif  \n",
            "  inflating: MCL/sj-05-768_001.tif   \n",
            "  inflating: MCL/sj-05-768_002.tif   \n",
            "  inflating: MCL/sj-05-768_003.tif   \n",
            "  inflating: MCL/sj-05-768_004.tif   \n",
            "  inflating: MCL/sj-05-768_005.tif   \n",
            "  inflating: MCL/sj-05-768_006.tif   \n",
            "  inflating: MCL/sj-05-768_007.tif   \n",
            "  inflating: MCL/sj-05-768_008.tif   \n",
            "  inflating: MCL/sj-05-768_009.tif   \n",
            "  inflating: MCL/sj-05-768_010.tif   \n",
            "  inflating: MCL/sj-05-768_011.tif   \n",
            "  inflating: MCL/sj-05-768_012.tif   \n",
            "  inflating: MCL/sj-05-768_013.tif   \n",
            "  inflating: MCL/sj-05-768_014.tif   \n",
            "  inflating: MCL/sj-05-768_015.tif   \n",
            "  inflating: MCL/sj-05-901-R1_001.tif  \n",
            "  inflating: MCL/sj-05-901-R1_002.tif  \n",
            "  inflating: MCL/sj-05-901-R1_003.tif  \n",
            "  inflating: MCL/sj-05-901-R1_004.tif  \n",
            "  inflating: MCL/sj-05-901-R1_005.tif  \n",
            "  inflating: MCL/sj-05-901-R1_006.tif  \n",
            "  inflating: MCL/sj-05-901-R1_007.tif  \n",
            "  inflating: MCL/sj-05-901-R1_008.tif  \n",
            "  inflating: MCL/sj-05-901-R1_009.tif  \n",
            "  inflating: MCL/sj-05-901-R1_010.tif  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx4EIWfmV4vh",
        "outputId": "76ac82ab-5e12-4aa9-b2b5-ec26c2ef6854",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive\t\t\tLinks.gdoc\n",
            "CLL\t\t\tmalignant-lymphoma-classification.zip\n",
            "Data_Entry_2017.gsheet\tMCL\n",
            "FL\t\t\tsimclr_finetune.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKgMFsGdUtUs"
      },
      "source": [
        "# Ref: https://github.com/google-research/simclr/blob/master/colabs/finetuning.ipynb\n",
        "#@title Preprocessing functions from data_util.py in SimCLR repository (hidden).\n",
        "\n",
        "FLAGS_color_jitter_strength = 0.3\n",
        "CROP_PROPORTION = 0.875  # Standard for ImageNet.\n",
        "\n",
        "\n",
        "def random_apply(func, p, x):\n",
        "  \"\"\"Randomly apply function func to x with probability p.\"\"\"\n",
        "  return tf.cond(\n",
        "      tf.less(tf.random_uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
        "              tf.cast(p, tf.float32)),\n",
        "      lambda: func(x),\n",
        "      lambda: x)\n",
        "\n",
        "\n",
        "def random_brightness(image, max_delta, impl='simclrv2'):\n",
        "  \"\"\"A multiplicative vs additive change of brightness.\"\"\"\n",
        "  if impl == 'simclrv2':\n",
        "    factor = tf.random_uniform(\n",
        "        [], tf.maximum(1.0 - max_delta, 0), 1.0 + max_delta)\n",
        "    image = image * factor\n",
        "  elif impl == 'simclrv1':\n",
        "    image = random_brightness(image, max_delta=max_delta)\n",
        "  else:\n",
        "    raise ValueError('Unknown impl {} for random brightness.'.format(impl))\n",
        "  return image\n",
        "\n",
        "\n",
        "def to_grayscale(image, keep_channels=True):\n",
        "  image = tf.image.rgb_to_grayscale(image)\n",
        "  if keep_channels:\n",
        "    image = tf.tile(image, [1, 1, 3])\n",
        "  return image\n",
        "\n",
        "\n",
        "def color_jitter(image,\n",
        "                 strength,\n",
        "                 random_order=True):\n",
        "  \"\"\"Distorts the color of the image.\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    strength: the floating number for the strength of the color augmentation.\n",
        "    random_order: A bool, specifying whether to randomize the jittering order.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  brightness = 0.8 * strength\n",
        "  contrast = 0.8 * strength\n",
        "  saturation = 0.8 * strength\n",
        "  hue = 0.2 * strength\n",
        "  if random_order:\n",
        "    return color_jitter_rand(image, brightness, contrast, saturation, hue)\n",
        "  else:\n",
        "    return color_jitter_nonrand(image, brightness, contrast, saturation, hue)\n",
        "\n",
        "\n",
        "def color_jitter_nonrand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is fixed).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x, brightness, contrast, saturation, hue):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      if brightness != 0 and i == 0:\n",
        "        x = random_brightness(x, max_delta=brightness)\n",
        "      elif contrast != 0 and i == 1:\n",
        "        x = tf.image.random_contrast(\n",
        "            x, lower=1-contrast, upper=1+contrast)\n",
        "      elif saturation != 0 and i == 2:\n",
        "        x = tf.image.random_saturation(\n",
        "            x, lower=1-saturation, upper=1+saturation)\n",
        "      elif hue != 0:\n",
        "        x = tf.image.random_hue(x, max_delta=hue)\n",
        "      return x\n",
        "\n",
        "    for i in range(4):\n",
        "      image = apply_transform(i, image, brightness, contrast, saturation, hue)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def color_jitter_rand(image, brightness=0, contrast=0, saturation=0, hue=0):\n",
        "  \"\"\"Distorts the color of the image (jittering order is random).\n",
        "  Args:\n",
        "    image: The input image tensor.\n",
        "    brightness: A float, specifying the brightness for color jitter.\n",
        "    contrast: A float, specifying the contrast for color jitter.\n",
        "    saturation: A float, specifying the saturation for color jitter.\n",
        "    hue: A float, specifying the hue for color jitter.\n",
        "  Returns:\n",
        "    The distorted image tensor.\n",
        "  \"\"\"\n",
        "  with tf.name_scope('distort_color'):\n",
        "    def apply_transform(i, x):\n",
        "      \"\"\"Apply the i-th transformation.\"\"\"\n",
        "      def brightness_foo():\n",
        "        if brightness == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return random_brightness(x, max_delta=brightness)\n",
        "      def contrast_foo():\n",
        "        if contrast == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_contrast(x, lower=1-contrast, upper=1+contrast)\n",
        "      def saturation_foo():\n",
        "        if saturation == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_saturation(\n",
        "              x, lower=1-saturation, upper=1+saturation)\n",
        "      def hue_foo():\n",
        "        if hue == 0:\n",
        "          return x\n",
        "        else:\n",
        "          return tf.image.random_hue(x, max_delta=hue)\n",
        "      x = tf.cond(tf.less(i, 2),\n",
        "                  lambda: tf.cond(tf.less(i, 1), brightness_foo, contrast_foo),\n",
        "                  lambda: tf.cond(tf.less(i, 3), saturation_foo, hue_foo))\n",
        "      return x\n",
        "\n",
        "    perm = tf.random_shuffle(tf.range(4))\n",
        "    for i in range(4):\n",
        "      image = apply_transform(perm[i], image)\n",
        "      image = tf.clip_by_value(image, 0., 1.)\n",
        "    return image\n",
        "\n",
        "\n",
        "def _compute_crop_shape(\n",
        "    image_height, image_width, aspect_ratio, crop_proportion):\n",
        "  \"\"\"Compute aspect ratio-preserving shape for central crop.\n",
        "  The resulting shape retains `crop_proportion` along one side and a proportion\n",
        "  less than or equal to `crop_proportion` along the other side.\n",
        "  Args:\n",
        "    image_height: Height of image to be cropped.\n",
        "    image_width: Width of image to be cropped.\n",
        "    aspect_ratio: Desired aspect ratio (width / height) of output.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    crop_height: Height of image after cropping.\n",
        "    crop_width: Width of image after cropping.\n",
        "  \"\"\"\n",
        "  image_width_float = tf.cast(image_width, tf.float32)\n",
        "  image_height_float = tf.cast(image_height, tf.float32)\n",
        "\n",
        "  def _requested_aspect_ratio_wider_than_image():\n",
        "    crop_height = tf.cast(tf.rint(\n",
        "        crop_proportion / aspect_ratio * image_width_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * image_width_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  def _image_wider_than_requested_aspect_ratio():\n",
        "    crop_height = tf.cast(\n",
        "        tf.rint(crop_proportion * image_height_float), tf.int32)\n",
        "    crop_width = tf.cast(tf.rint(\n",
        "        crop_proportion * aspect_ratio *\n",
        "        image_height_float), tf.int32)\n",
        "    return crop_height, crop_width\n",
        "\n",
        "  return tf.cond(\n",
        "      aspect_ratio > image_width_float / image_height_float,\n",
        "      _requested_aspect_ratio_wider_than_image,\n",
        "      _image_wider_than_requested_aspect_ratio)\n",
        "\n",
        "\n",
        "def center_crop(image, height, width, crop_proportion):\n",
        "  \"\"\"Crops to center of image and rescales to desired size.\n",
        "  Args:\n",
        "    image: Image Tensor to crop.\n",
        "    height: Height of image to be cropped.\n",
        "    width: Width of image to be cropped.\n",
        "    crop_proportion: Proportion of image to retain along the less-cropped side.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a central crop of `image`.\n",
        "  \"\"\"\n",
        "  shape = tf.shape(image)\n",
        "  image_height = shape[0]\n",
        "  image_width = shape[1]\n",
        "  crop_height, crop_width = _compute_crop_shape(\n",
        "      image_height, image_width, height / width, crop_proportion)\n",
        "  offset_height = ((image_height - crop_height) + 1) // 2\n",
        "  offset_width = ((image_width - crop_width) + 1) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_height, offset_width, crop_height, crop_width)\n",
        "\n",
        "  image = tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "  return image\n",
        "\n",
        "\n",
        "def distorted_bounding_box_crop(image,\n",
        "                                bbox,\n",
        "                                min_object_covered=0.1,\n",
        "                                aspect_ratio_range=(0.75, 1.33),\n",
        "                                area_range=(0.05, 1.0),\n",
        "                                max_attempts=100,\n",
        "                                scope=None):\n",
        "  \"\"\"Generates cropped_image using one of the bboxes randomly distorted.\n",
        "  See `tf.image.sample_distorted_bounding_box` for more documentation.\n",
        "  Args:\n",
        "    image: `Tensor` of image data.\n",
        "    bbox: `Tensor` of bounding boxes arranged `[1, num_boxes, coords]`\n",
        "        where each coordinate is [0, 1) and the coordinates are arranged\n",
        "        as `[ymin, xmin, ymax, xmax]`. If num_boxes is 0 then use the whole\n",
        "        image.\n",
        "    min_object_covered: An optional `float`. Defaults to `0.1`. The cropped\n",
        "        area of the image must contain at least this fraction of any bounding\n",
        "        box supplied.\n",
        "    aspect_ratio_range: An optional list of `float`s. The cropped area of the\n",
        "        image must have an aspect ratio = width / height within this range.\n",
        "    area_range: An optional list of `float`s. The cropped area of the image\n",
        "        must contain a fraction of the supplied image within in this range.\n",
        "    max_attempts: An optional `int`. Number of attempts at generating a cropped\n",
        "        region of the image of the specified constraints. After `max_attempts`\n",
        "        failures, return the entire image.\n",
        "    scope: Optional `str` for name scope.\n",
        "  Returns:\n",
        "    (cropped image `Tensor`, distorted bbox `Tensor`).\n",
        "  \"\"\"\n",
        "  with tf.name_scope(scope, 'distorted_bounding_box_crop', [image, bbox]):\n",
        "    shape = tf.shape(image)\n",
        "    sample_distorted_bounding_box = tf.image.sample_distorted_bounding_box(\n",
        "        shape,\n",
        "        bounding_boxes=bbox,\n",
        "        min_object_covered=min_object_covered,\n",
        "        aspect_ratio_range=aspect_ratio_range,\n",
        "        area_range=area_range,\n",
        "        max_attempts=max_attempts,\n",
        "        use_image_if_no_bounding_boxes=True)\n",
        "    bbox_begin, bbox_size, _ = sample_distorted_bounding_box\n",
        "\n",
        "    # Crop the image to the specified bounding box.\n",
        "    offset_y, offset_x, _ = tf.unstack(bbox_begin)\n",
        "    target_height, target_width, _ = tf.unstack(bbox_size)\n",
        "    image = tf.image.crop_to_bounding_box(\n",
        "        image, offset_y, offset_x, target_height, target_width)\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def crop_and_resize(image, height, width):\n",
        "  \"\"\"Make a random crop and resize it to height `height` and width `width`.\n",
        "  Args:\n",
        "    image: Tensor representing the image.\n",
        "    height: Desired image height.\n",
        "    width: Desired image width.\n",
        "  Returns:\n",
        "    A `height` x `width` x channels Tensor holding a random crop of `image`.\n",
        "  \"\"\"\n",
        "  bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
        "  aspect_ratio = width / height\n",
        "  image = distorted_bounding_box_crop(\n",
        "      image,\n",
        "      bbox,\n",
        "      min_object_covered=0.1,\n",
        "      aspect_ratio_range=(3. / 4 * aspect_ratio, 4. / 3. * aspect_ratio),\n",
        "      area_range=(0.08, 1.0),\n",
        "      max_attempts=100,\n",
        "      scope=None)\n",
        "  return tf.image.resize_bicubic([image], [height, width])[0]\n",
        "\n",
        "\n",
        "def gaussian_blur(image, kernel_size, sigma, padding='SAME'):\n",
        "  \"\"\"Blurs the given image with separable convolution.\n",
        "  Args:\n",
        "    image: Tensor of shape [height, width, channels] and dtype float to blur.\n",
        "    kernel_size: Integer Tensor for the size of the blur kernel. This is should\n",
        "      be an odd number. If it is an even number, the actual kernel size will be\n",
        "      size + 1.\n",
        "    sigma: Sigma value for gaussian operator.\n",
        "    padding: Padding to use for the convolution. Typically 'SAME' or 'VALID'.\n",
        "  Returns:\n",
        "    A Tensor representing the blurred image.\n",
        "  \"\"\"\n",
        "  radius = tf.to_int32(kernel_size / 2)\n",
        "  kernel_size = radius * 2 + 1\n",
        "  x = tf.to_float(tf.range(-radius, radius + 1))\n",
        "  blur_filter = tf.exp(\n",
        "      -tf.pow(x, 2.0) / (2.0 * tf.pow(tf.to_float(sigma), 2.0)))\n",
        "  blur_filter /= tf.reduce_sum(blur_filter)\n",
        "  # One vertical and one horizontal filter.\n",
        "  blur_v = tf.reshape(blur_filter, [kernel_size, 1, 1, 1])\n",
        "  blur_h = tf.reshape(blur_filter, [1, kernel_size, 1, 1])\n",
        "  num_channels = tf.shape(image)[-1]\n",
        "  blur_h = tf.tile(blur_h, [1, 1, num_channels, 1])\n",
        "  blur_v = tf.tile(blur_v, [1, 1, num_channels, 1])\n",
        "  expand_batch_dim = image.shape.ndims == 3\n",
        "  if expand_batch_dim:\n",
        "    # Tensorflow requires batched input to convolutions, which we can fake with\n",
        "    # an extra dimension.\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      image, blur_h, strides=[1, 1, 1, 1], padding=padding)\n",
        "  blurred = tf.nn.depthwise_conv2d(\n",
        "      blurred, blur_v, strides=[1, 1, 1, 1], padding=padding)\n",
        "  if expand_batch_dim:\n",
        "    blurred = tf.squeeze(blurred, axis=0)\n",
        "  return blurred\n",
        "\n",
        "\n",
        "def random_crop_with_resize(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly crop and resize an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: Probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  def _transform(image):  # pylint: disable=missing-docstring\n",
        "    image = crop_and_resize(image, height, width)\n",
        "    return image\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_color_jitter(image, p=1.0):\n",
        "  def _transform(image):\n",
        "    color_jitter_t = functools.partial(\n",
        "        color_jitter, strength=FLAGS_color_jitter_strength)\n",
        "    image = random_apply(color_jitter_t, p=0.8, x=image)\n",
        "    return random_apply(to_grayscale, p=0.2, x=image)\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def random_blur(image, height, width, p=1.0):\n",
        "  \"\"\"Randomly blur an image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    p: probability of applying this transformation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  del width\n",
        "  def _transform(image):\n",
        "    sigma = tf.random.uniform([], 0.1, 2.0, dtype=tf.float32)\n",
        "    return gaussian_blur(\n",
        "        image, kernel_size=height//10, sigma=sigma, padding='SAME')\n",
        "  return random_apply(_transform, p=p, x=image)\n",
        "\n",
        "\n",
        "def batch_random_blur(images_list, height, width, blur_probability=0.5):\n",
        "  \"\"\"Apply efficient batch data transformations.\n",
        "  Args:\n",
        "    images_list: a list of image tensors.\n",
        "    height: the height of image.\n",
        "    width: the width of image.\n",
        "    blur_probability: the probaility to apply the blur operator.\n",
        "  Returns:\n",
        "    Preprocessed feature list.\n",
        "  \"\"\"\n",
        "  def generate_selector(p, bsz):\n",
        "    shape = [bsz, 1, 1, 1]\n",
        "    selector = tf.cast(\n",
        "        tf.less(tf.random_uniform(shape, 0, 1, dtype=tf.float32), p),\n",
        "        tf.float32)\n",
        "    return selector\n",
        "\n",
        "  new_images_list = []\n",
        "  for images in images_list:\n",
        "    images_new = random_blur(images, height, width, p=1.)\n",
        "    selector = generate_selector(blur_probability, tf.shape(images)[0])\n",
        "    images = images_new * selector + images * (1 - selector)\n",
        "    images = tf.clip_by_value(images, 0., 1.)\n",
        "    new_images_list.append(images)\n",
        "\n",
        "  return new_images_list\n",
        "\n",
        "\n",
        "def preprocess_for_train(image, height, width,\n",
        "                         color_distort=True, crop=True, flip=True):\n",
        "  \"\"\"Preprocesses the given image for training.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    color_distort: Whether to apply the color distortion.\n",
        "    crop: Whether to crop the image.\n",
        "    flip: Whether or not to flip left and right of an image.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = random_crop_with_resize(image, height, width)\n",
        "  if flip:\n",
        "    image = tf.image.random_flip_left_right(image)\n",
        "  if color_distort:\n",
        "    image = random_color_jitter(image)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_for_eval(image, height, width, crop=True):\n",
        "  \"\"\"Preprocesses the given image for evaluation.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    crop: Whether or not to (center) crop the test images.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor`.\n",
        "  \"\"\"\n",
        "  if crop:\n",
        "    image = center_crop(image, height, width, crop_proportion=CROP_PROPORTION)\n",
        "  image = tf.reshape(image, [height, width, 3])\n",
        "  image = tf.clip_by_value(image, 0., 1.)\n",
        "  return image\n",
        "\n",
        "\n",
        "def preprocess_image(image, height, width, is_training=False,\n",
        "                     color_distort=True, test_crop=True):\n",
        "  \"\"\"Preprocesses the given image.\n",
        "  Args:\n",
        "    image: `Tensor` representing an image of arbitrary size.\n",
        "    height: Height of output image.\n",
        "    width: Width of output image.\n",
        "    is_training: `bool` for whether the preprocessing is for training.\n",
        "    color_distort: whether to apply the color distortion.\n",
        "    test_crop: whether or not to extract a central crop of the images\n",
        "        (as for standard ImageNet evaluation) during the evaluation.\n",
        "  Returns:\n",
        "    A preprocessed image `Tensor` of range [0, 1].\n",
        "  \"\"\"\n",
        "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
        "  if is_training:\n",
        "    return preprocess_for_train(image, height, width, color_distort)\n",
        "  else:\n",
        "    return preprocess_for_eval(image, height, width, test_crop)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7Eqpe3SVDPj"
      },
      "source": [
        "#Ref: https://github.com/google-research/simclr/blob/master/colabs/finetuning.ipynb\n",
        "#@title LARS optimizer from data_util.py in SimCLR repository (hidden).\n",
        "\n",
        "EETA_DEFAULT = 0.001\n",
        "\n",
        "class LARSOptimizer(tf.train.Optimizer):\n",
        "  \"\"\"Layer-wise Adaptive Rate Scaling for large batch training.\n",
        "\n",
        "  Introduced by \"Large Batch Training of Convolutional Networks\" by Y. You,\n",
        "  I. Gitman, and B. Ginsburg. (https://arxiv.org/abs/1708.03888)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               learning_rate,\n",
        "               momentum=0.9,\n",
        "               use_nesterov=False,\n",
        "               weight_decay=0.0,\n",
        "               exclude_from_weight_decay=None,\n",
        "               exclude_from_layer_adaptation=None,\n",
        "               classic_momentum=True,\n",
        "               eeta=EETA_DEFAULT,\n",
        "               name=\"LARSOptimizer\"):\n",
        "    \"\"\"Constructs a LARSOptimizer.\n",
        "\n",
        "    Args:\n",
        "      learning_rate: A `float` for learning rate.\n",
        "      momentum: A `float` for momentum.\n",
        "      use_nesterov: A 'Boolean' for whether to use nesterov momentum.\n",
        "      weight_decay: A `float` for weight decay.\n",
        "      exclude_from_weight_decay: A list of `string` for variable screening, if\n",
        "          any of the string appears in a variable's name, the variable will be\n",
        "          excluded for computing weight decay. For example, one could specify\n",
        "          the list like ['batch_normalization', 'bias'] to exclude BN and bias\n",
        "          from weight decay.\n",
        "      exclude_from_layer_adaptation: Similar to exclude_from_weight_decay, but\n",
        "          for layer adaptation. If it is None, it will be defaulted the same as\n",
        "          exclude_from_weight_decay.\n",
        "      classic_momentum: A `boolean` for whether to use classic (or popular)\n",
        "          momentum. The learning rate is applied during momeuntum update in\n",
        "          classic momentum, but after momentum for popular momentum.\n",
        "      eeta: A `float` for scaling of learning rate when computing trust ratio.\n",
        "      name: The name for the scope.\n",
        "    \"\"\"\n",
        "    super(LARSOptimizer, self).__init__(False, name)\n",
        "\n",
        "    self.learning_rate = learning_rate\n",
        "    self.momentum = momentum\n",
        "    self.weight_decay = weight_decay\n",
        "    self.use_nesterov = use_nesterov\n",
        "    self.classic_momentum = classic_momentum\n",
        "    self.eeta = eeta\n",
        "    self.exclude_from_weight_decay = exclude_from_weight_decay\n",
        "    # exclude_from_layer_adaptation is set to exclude_from_weight_decay if the\n",
        "    # arg is None.\n",
        "    if exclude_from_layer_adaptation:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_layer_adaptation\n",
        "    else:\n",
        "      self.exclude_from_layer_adaptation = exclude_from_weight_decay\n",
        "\n",
        "  def apply_gradients(self, grads_and_vars, global_step=None, name=None):\n",
        "    if global_step is None:\n",
        "      global_step = tf.train.get_or_create_global_step()\n",
        "    new_global_step = global_step + 1\n",
        "\n",
        "    assignments = []\n",
        "    for (grad, param) in grads_and_vars:\n",
        "      if grad is None or param is None:\n",
        "        continue\n",
        "\n",
        "      param_name = param.op.name\n",
        "\n",
        "      v = tf.get_variable(\n",
        "          name=param_name + \"/Momentum\",\n",
        "          shape=param.shape.as_list(),\n",
        "          dtype=tf.float32,\n",
        "          trainable=False,\n",
        "          initializer=tf.zeros_initializer())\n",
        "\n",
        "      if self._use_weight_decay(param_name):\n",
        "        grad += self.weight_decay * param\n",
        "\n",
        "      if self.classic_momentum:\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          g_norm = tf.norm(grad, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(g_norm, 0), (self.eeta * w_norm / g_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = self.learning_rate * trust_ratio\n",
        "\n",
        "        next_v = tf.multiply(self.momentum, v) + scaled_lr * grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + scaled_lr * grad\n",
        "        else:\n",
        "          update = next_v\n",
        "        next_param = param - update\n",
        "      else:\n",
        "        next_v = tf.multiply(self.momentum, v) + grad\n",
        "        if self.use_nesterov:\n",
        "          update = tf.multiply(self.momentum, next_v) + grad\n",
        "        else:\n",
        "          update = next_v\n",
        "\n",
        "        trust_ratio = 1.0\n",
        "        if self._do_layer_adaptation(param_name):\n",
        "          w_norm = tf.norm(param, ord=2)\n",
        "          v_norm = tf.norm(update, ord=2)\n",
        "          trust_ratio = tf.where(\n",
        "              tf.greater(w_norm, 0), tf.where(\n",
        "                  tf.greater(v_norm, 0), (self.eeta * w_norm / v_norm),\n",
        "                  1.0),\n",
        "              1.0)\n",
        "        scaled_lr = trust_ratio * self.learning_rate\n",
        "        next_param = param - scaled_lr * update\n",
        "\n",
        "      assignments.extend(\n",
        "          [param.assign(next_param),\n",
        "           v.assign(next_v),\n",
        "           global_step.assign(new_global_step)])\n",
        "    return tf.group(*assignments, name=name)\n",
        "\n",
        "  def _use_weight_decay(self, param_name):\n",
        "    \"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"\n",
        "    if not self.weight_decay:\n",
        "      return False\n",
        "    if self.exclude_from_weight_decay:\n",
        "      for r in self.exclude_from_weight_decay:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True\n",
        "\n",
        "  def _do_layer_adaptation(self, param_name):\n",
        "    \"\"\"Whether to do layer-wise learning rate adaptation for `param_name`.\"\"\"\n",
        "    if self.exclude_from_layer_adaptation:\n",
        "      for r in self.exclude_from_layer_adaptation:\n",
        "        if re.search(r, param_name) is not None:\n",
        "          return False\n",
        "    return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdVDB7DVfcf"
      },
      "source": [
        "# load both csvs that contain labels into dataframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Requ8_oXW95u"
      },
      "source": [
        "# Create tf dataset objects compatible with the model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETGDKAgBb7GV"
      },
      "source": [
        "##Prepare Training Data\n",
        "\n",
        "Here we split the data into training and validation sets and create a single vector (disease_vec) with the 0/1 outputs for the disease status (what the model will try and predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr4EWf05t__3"
      },
      "source": [
        "Need to load the dataset into an object that i can create an iterator out of\n",
        "https://www.tensorflow.org/guide/data\n",
        "\n",
        "The training loop uses one example at a time with image as the feature and one-hot encoded vector as the label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsVBtagk4MAx"
      },
      "source": [
        "Create tf.data.Dataset object with all images and labels. It contains map and batch methods as used in the simclr finetuning colab\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset#args_1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7i43XAzmFTK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15d468d3-a5dd-4edd-839e-65fd416229b6"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive\t\t\tLinks.gdoc\n",
            "CLL\t\t\tmalignant-lymphoma-classification.zip\n",
            "Data_Entry_2017.gsheet\tMCL\n",
            "FL\t\t\tsimclr_finetune.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2IWRoqVXTjW",
        "outputId": "c1b5ba32-9b2d-4eac-9a60-0878194d48a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls -1q ./CLL | wc -l\n",
        "!ls -1q ./FL | wc -l\n",
        "!ls -1q ./MCL | wc -l"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "113\n",
            "139\n",
            "122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icFndj8JdqBa"
      },
      "source": [
        "# https://stackoverflow.com/questions/37340129/tensorflow-training-on-my-own-image\n",
        "'''\n",
        "Use the answer above to create an array of all file names and another array with all the labels. Use columns in the pandas df above\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNkVIIXqWprv"
      },
      "source": [
        "labels_targets = {\"0\": \"CCL\", \"1\": \"FL\", \"2\": \"MCL\"}"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5jDAVllXGSP"
      },
      "source": [
        "Split the folder data into training and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSCX3ysQW0MO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm2AyLy4w1zU"
      },
      "source": [
        "## Alternative Datasets\n",
        "http://www.dermnet.com/\n",
        "\n",
        "https://www.kaggle.com/tourist55/alzheimers-dataset-4-class-of-images#26%20(26).jpg\n",
        "\n",
        "https://www.kaggle.com/andrewmvd/cancer-inst-segmentation-and-classification\n",
        "\n",
        "https://www.kaggle.com/paultimothymooney/blood-cells\n",
        "\n",
        "https://www.kaggle.com/andrewmvd/malignant-lymphoma-classification\n",
        "\n",
        "https://datasetsearch.research.google.com/ (previously searched: cancer image classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV3_1vgRV6J3"
      },
      "source": [
        "References:\n",
        "https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community\n",
        "\n",
        "https://github.com/google-research/simclr/blob/master/colabs/finetuning.ipynb"
      ]
    }
  ]
}